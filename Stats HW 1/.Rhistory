# Step 1: Randomly resample data points for each treatment 20000 times  (hint: you can use sample or replicate)
ExpandedPBR <- sample(my_dataset$pbr, 20000, replace = TRUE , prob = NULL)
ExpandedChecklist <- sample(my_dataset$checklist, 20000, replace = TRUE , prob = NULL)
# Step 2: Draw the histogram to compare the orignal with the bootstrap data for each treatment separately (hint: use `hist`)
hist(my_dataset$pbr)
hist(ExpandedPBR)
hist(my_dataset$checklist ~ ExpandedChecklist)
# Step 1: Randomly resample data points for each treatment 20000 times  (hint: you can use sample or replicate)
ExpandedPBR <- sample(my_dataset$pbr, 20000, replace = TRUE , prob = NULL)
ExpandedChecklist <- sample(my_dataset$checklist, 20000, replace = TRUE , prob = NULL)
# Step 2: Draw the histogram to compare the orignal with the bootstrap data for each treatment separately (hint: use `hist`)
hist(my_dataset$pbr)
hist(ExpandedPBR)
hist(my_dataset$checklist)
hist(ExpandedChecklist)
# Step 4: Check the normality of the bootstrapped data.
# from the visual method of the histograms we can tell that they are not sample but we can use AD test as well
ad.test(ExpandedPBR)
ad.test(ExpandedChecklist)
#from the AD test we have p-value < 2.2e-16 --> the null hypothesis that the data are normally distributed is rejected
# Step 4: Compare the descriptive statistics of original with the bootstrapped data.
mean(my_dataset$pbr)
mean(my_dataset$checklist)
mean(ExpandedPBR)
mean(ExpandedChecklist)
median(my_dataset$pbr)
median(my_dataset$checklist)
median(ExpandedPBR)
median(ExpandedChecklist)
boxplot(my_dataset$pbr, my_dataset$checklist, ExpandedPBR, ExpandedChecklist)
View(my_dataset)
View(my_dataset)
#code goes here (hint: use melt or reshape)
install.packages("reshape2")
install.packages("reshape2")
#code goes here (hint: use melt or reshape)
install.packages("reshape2")
library("reshape2")
melted <- melt(my_dataset, id.vars=c("treatment", "time"))
#code goes here (hint: use melt or reshape)
install.packages("reshape2")
library("reshape2")
melted <- melt(my_dataset, id.vars=c("pbr", "checklist"))
install.packages("reshape2")
require(ggplot2)
install.packages("reshape2")
install.packages('nortest')
#code goes here (hint: use melt or reshape)
library("reshape2")
melted <- melt(my_dataset, id.vars=c("pbr", "checklist"))
#code goes here (hint: use melt or reshape)
library("reshape2")
melted <- melt(my_dataset, id.vars=c("pbr", "checklist"))
View(melted)
View(melted)
#code goes here (hint: use melt or reshape)
library("reshape2")
melted <- melt(my_dataset)
View(melted)
View(melted)
View(my_dataset)
View(my_dataset)
knitr::opts_chunk$set(echo = TRUE, tidy.opts = list(width.cutoff = 60), tidy = TRUE)
library(Sleuth3) # example datasets from textbook, "The Statistical Sleuth - A Course in
# Methods of Data Analysis (3rd Edition)"
library(reshape2) # for formatting and aggregation of data frames
library(ggplot2) # for creating graphs
library(dplyr) # for data manipulation and clean-up
library(plotly) # for creating interactive web graphics from ggplot2 graphs
library(knitr) # required for generating PDF output
library(modeest) # required for `mfv()` function
BookStore <- data.frame(
Price=c(99.34, 51.53, 20.45, 97.22, 61.89, 58.17, 61.63, 44.63, 96.69, 48.88,
55.98, 38.82, 45.14, 70.99, 48.85, 67.49, 53.90, 42.01, 61.35, 55.75),
Genre=factor(c('Science', 'Engineering', 'Art', 'Science', 'Math', 'Engineering', 'Art', 'Math', 'Engineering', 'Art',
'Math', 'Art', 'Art', 'Engineering', 'Math', 'Science', 'Engineering', 'Art', 'Science', 'Math'))
)
BookStore
knitr::opts_chunk$set(echo = TRUE, tidy.opts = list(width.cutoff = 60), tidy = TRUE)
library(Sleuth3) # example datasets from textbook, "The Statistical Sleuth - A Course in
# Methods of Data Analysis (3rd Edition)"
library(reshape2) # for formatting and aggregation of data frames
library(ggplot2) # for creating graphs
library(dplyr) # for data manipulation and clean-up
library(plotly) # for creating interactive web graphics from ggplot2 graphs
library(knitr) # required for generating PDF output
library(modeest) # required for `mfv()` function
Prices <- c(99.34, 51.53, 20.45, 97.22, 61.89, 58.17, 61.63, 44.63, 96.69, 48.88)
Prices
# checking the type of the Prices variable
typeof(Prices)
# checking whether the Prices variable is a dataframe
is.data.frame(Prices)
# the `mu` option indicates the true value of the mean, i.e. the mean price of all books in the OSU bookstore
t.test(BookStore$Price, mu = 85, alternative = "two.sided")
Amazon <- data.frame(
Price=c(31.87, 58.94, 40.39, 117.99, 108.29, 78.44, 103.94, 96.44, 65.74, 63.49,
55.19, 92.65, 35.55, 104.49, 97.89, 74.87, 89.99, 19.99, 58.19, 80.89),
Genre=factor(c('Poetry', 'Mathematics', 'Psychology', 'Medical', 'Biology', 'Mathematics', 'Literature', 'Medical', 'Linguistics', 'Accounting',
'Physics', 'Psychology', 'Poetry', 'Medical', 'Medical', 'Literature', 'Accounting', 'Mathematics', 'Literature', 'Biology'))
)
Comparison <- data.frame(Store=rep(c("Bookstore", "Amazon"), each=20), Price=c(BookStore$Price, Amazon$Price), Genre=c(BookStore$Genre, Amazon$Genre))
Comparison
# t.test(weight ~ group)
t.test(Comparison$Price ~ Comparison$Store)
BeforeAmazon <- c(92.99, 50.98, 24.14, 101.50, 45.59, 69.95, 64.69, 58.29, 120.22, 49.90,
52.99, 47.25, 54.99, 80.00, 62.65, 69.59, 57.35, 40.95, 82.84, 63.29)
AfterAmazon <- BookStore$Price
t.test(BeforeAmazon, AfterAmazon, paired=TRUE)
# note: the one-sample t-test that we examined earlier also used a "two-sided" alternative, but compared against a fixed mean from the population
t.test(Comparison$Price ~ Comparison$Store, alternative = "two.sided", var.equal = FALSE)
t.test(Comparison$Price ~ Comparison$Store, alternative = "greater", var.equal = FALSE)
t.test(Comparison$Price ~ Comparison$Store, alternative = "less", var.equal = FALSE)
# setting `var.equal = TRUE` results in a pooled variance
# Setting the variances to be equal simplifies variance estimation and increases the power of the test, but can cause severely miscalculated variances when the means are in fact different.
# Always allow the variances to be estimated for finite sample sizes by setting `var.equal = FALSE`.
# code goes here
t.test(my_dataset$pbr ~ my_dataset$checklist, alternative = "two.sided", var.equal = FALSE)
View(Amazon)
View(Amazon)
View(my_dataset)
View(my_dataset)
View(Comparison)
View(Comparison)
#code goes here (hint: use melt or reshape)
library("reshape2")
melted <- melt(my_dataset)
Comparison <- data.frame(Treatment=rep(c("pbr", "checklist"), each=30), time=c(my_dataset$pbr, my_dataset$checklist))
Comparison
View(Comparison)
View(Comparison)
#code goes here (hint: use melt or reshape)
library("reshape2")
melted <- melt(my_dataset)
Comparison <- data.frame(treatment=rep(c("pbr", "checklist"), each=30), time=c(my_dataset$pbr, my_dataset$checklist))
Comparison
# code goes here
t.test(Comparison$treatment ~ Comparison$time, alternative = "two.sided", var.equal = FALSE)
# code goes here
t.test(Comparison$treatment , Comparison$time, alternative = "two.sided", var.equal = FALSE)
# code goes here
t.test(Comparison$treatment ~ Comparison$time, alternative = "two.sided", var.equal = FALSE)
# note: the one-sample t-test that we examined earlier also used a "two-sided" alternative, but compared against a fixed mean from the population
t.test(Comparison$Price ~ Comparison$Store, alternative = "two.sided", var.equal = FALSE)
#code goes here (hint: use melt or reshape)
library("reshape2")
melted <- melt(my_dataset)
Compare <- data.frame(treatment=rep(c("pbr", "checklist"), each=30), time=c(my_dataset$pbr, my_dataset$checklist))
Compare
knitr::opts_chunk$set(echo = TRUE, tidy.opts = list(width.cutoff = 60), tidy = TRUE)
library(Sleuth3) # example datasets from textbook, "The Statistical Sleuth - A Course in
# Methods of Data Analysis (3rd Edition)"
library(reshape2) # for formatting and aggregation of data frames
library(ggplot2) # for creating graphs
library(dplyr) # for data manipulation and clean-up
library(plotly) # for creating interactive web graphics from ggplot2 graphs
library(knitr) # required for generating PDF output
library(modeest) # required for `mfv()` function
BookStore <- data.frame(
Price=c(99.34, 51.53, 20.45, 97.22, 61.89, 58.17, 61.63, 44.63, 96.69, 48.88,
55.98, 38.82, 45.14, 70.99, 48.85, 67.49, 53.90, 42.01, 61.35, 55.75),
Genre=factor(c('Science', 'Engineering', 'Art', 'Science', 'Math', 'Engineering', 'Art', 'Math', 'Engineering', 'Art',
'Math', 'Art', 'Art', 'Engineering', 'Math', 'Science', 'Engineering', 'Art', 'Science', 'Math'))
)
BookStore
# the `mu` option indicates the true value of the mean, i.e. the mean price of all books in the OSU bookstore
t.test(BookStore$Price, mu = 85, alternative = "two.sided")
# code goes here
t.test(Compare$treatment ~ Compare$time, alternative = "two.sided", var.equal = FALSE)
# note: the one-sample t-test that we examined earlier also used a "two-sided" alternative, but compared against a fixed mean from the population
t.test(Comparison$Price ~ Comparison$Store, alternative = "two.sided", var.equal = FALSE)
# note: the one-sample t-test that we examined earlier also used a "two-sided" alternative, but compared against a fixed mean from the population
t.test(Comparison$Price ~ Comparison$Store, alternative = "two.sided", var.equal = FALSE)
View(Comparison)
View(Comparison)
Amazon <- data.frame(
Price=c(31.87, 58.94, 40.39, 117.99, 108.29, 78.44, 103.94, 96.44, 65.74, 63.49,
55.19, 92.65, 35.55, 104.49, 97.89, 74.87, 89.99, 19.99, 58.19, 80.89),
Genre=factor(c('Poetry', 'Mathematics', 'Psychology', 'Medical', 'Biology', 'Mathematics', 'Literature', 'Medical', 'Linguistics', 'Accounting',
'Physics', 'Psychology', 'Poetry', 'Medical', 'Medical', 'Literature', 'Accounting', 'Mathematics', 'Literature', 'Biology'))
)
Comparison <- data.frame(Store=rep(c("Bookstore", "Amazon"), each=20), Price=c(BookStore$Price, Amazon$Price), Genre=c(BookStore$Genre, Amazon$Genre))
Comparison
# t.test(weight ~ group)
t.test(Comparison$Price ~ Comparison$Store)
View(Comparison)
View(Comparison)
View(Compare)
View(Compare)
BeforeAmazon <- c(92.99, 50.98, 24.14, 101.50, 45.59, 69.95, 64.69, 58.29, 120.22, 49.90,
52.99, 47.25, 54.99, 80.00, 62.65, 69.59, 57.35, 40.95, 82.84, 63.29)
AfterAmazon <- BookStore$Price
t.test(BeforeAmazon, AfterAmazon, paired=TRUE)
# note: the one-sample t-test that we examined earlier also used a "two-sided" alternative, but compared against a fixed mean from the population
t.test(Comparison$Price ~ Comparison$Store, alternative = "two.sided", var.equal = FALSE)
t.test(Comparison$Price ~ Comparison$Store, alternative = "greater", var.equal = FALSE)
t.test(Comparison$Price ~ Comparison$Store, alternative = "less", var.equal = FALSE)
# setting `var.equal = TRUE` results in a pooled variance
# Setting the variances to be equal simplifies variance estimation and increases the power of the test, but can cause severely miscalculated variances when the means are in fact different.
# Always allow the variances to be estimated for finite sample sizes by setting `var.equal = FALSE`.
#code goes here (hint: use melt or reshape)
library("reshape2")
melted <- melt(my_dataset)
Compare <- data.frame(treatment=rep(c("pbr", "checklist"), each=30), time=c(my_dataset$pbr, my_dataset$checklist))
Compare
# code goes here
t.test(Compare$treatment ~ Compare$time, alternative = "two.sided", var.equal = FALSE)
#code goes here (hint: use melt or reshape)
library("reshape2")
melted <- melt(my_dataset)
Compare <- data.frame(treatment=rep(c("pbr", "checklist"), each=30), time=c(my_dataset$pbr, my_dataset$checklist), , time=c(my_dataset$pbr, my_dataset$checklist))
#code goes here (hint: use melt or reshape)
library("reshape2")
melted <- melt(my_dataset)
Compare <- data.frame(treatment=rep(c("pbr", "checklist"), each=30), time=c(my_dataset$pbr, my_dataset$checklist), , timer=c(my_dataset$pbr, my_dataset$checklist))
#code goes here (hint: use melt or reshape)
library("reshape2")
melted <- melt(my_dataset)
Compare <- data.frame(treatment=rep(c("pbr", "checklist"), each=30), time=c(my_dataset$pbr, my_dataset$checklist), timer=c(my_dataset$pbr, my_dataset$checklist))
Compare
# code goes here
t.test(Compare$treatment ~ Compare$time, alternative = "two.sided", var.equal = FALSE)
# code goes here
t.test(Compare$treatment ~ Compare$time, alternative = "two.sided", var.equal = FALSE)
# code goes here
t.test(Compare$treatment , Compare$time, alternative = "two.sided", var.equal = FALSE)
# code goes here
t.test(Compare$treatment ~ Compare$time, alternative = "two.sided", var.equal = FALSE)
View(melted)
View(melted)
#code goes here (hint: use melt or reshape)
library("reshape2")
melted <- melt(my_dataset)
Compare <- data.frame(treatment=rep(c("pbr", "checklist"), each=30), time=c(my_dataset$pbr, my_dataset$checklist))
Compare
# code goes here
t.test(Compare$treatment ~ Compare$time, alternative = "two.sided", var.equal = FALSE)
# code goes here
t.test(Compare$treatment, Compare$time, alternative = "two.sided", var.equal = FALSE)
# code goes here
t.test(Compare$treatment ~ Compare$time, alternative = "two.sided", var.equal = FALSE)
# code goes here
t.test(Compare$treatment , Compare$time, alternative = "two.sided", var.equal = FALSE)
# note: the one-sample t-test that we examined earlier also used a "two-sided" alternative, but compared against a fixed mean from the population
t.test(Comparison$Price , Comparison$Store, alternative = "two.sided", var.equal = FALSE)
# note: the one-sample t-test that we examined earlier also used a "two-sided" alternative, but compared against a fixed mean from the population
t.test(Comparison$Price ~ Comparison$Store, alternative = "two.sided", var.equal = FALSE)
t.test(Comparison$Price ~ Comparison$Store, alternative = "greater", var.equal = FALSE)
t.test(Comparison$Price ~ Comparison$Store, alternative = "less", var.equal = FALSE)
# setting `var.equal = TRUE` results in a pooled variance
# Setting the variances to be equal simplifies variance estimation and increases the power of the test, but can cause severely miscalculated variances when the means are in fact different.
# Always allow the variances to be estimated for finite sample sizes by setting `var.equal = FALSE`.
# code goes here
t.test(Comparison$Price ~ Comparison$Store, alternative = "greater", var.equal = FALSE)
# code goes here
t.test(Compare$treatment ~ Compare$time, alternative = "greater", var.equal = FALSE)
#code goes here (hint: use melt or reshape)
library("reshape2")
melted <- melt(my_dataset)
Compare <- data.frame(treatment=rep(c("pbr", "checklist"), each=30), time=c(my_dataset$pbr, my_dataset$checklist))
Compare$treatment
#code goes here (hint: use melt or reshape)
library("reshape2")
melted <- melt(my_dataset)
Compare <- data.frame(treatment=rep(c("pbr", "checklist"), each=30), time=c(my_dataset$pbr, my_dataset$checklist))
Compare
# code goes here
t.test(Compare$treatment, Compare$time, paired = TRUE, alternative = "two.sided")
# code goes here
t.test(Compare$treatment ~  Compare$time, paired = TRUE, alternative = "two.sided")
# code goes here
t.test(Compare$treatment, Compare$time, paired=TRUE)
# code goes here for all 3 cases
wilcox.test(Compare$treatment ~ Compare$time, mu=0, alt="two.sided", conf.int=T, conf.level=0.95, paired = F, exact=T, correct=T)
# code goes here
t.test(my_dataset$pbr ~ my_dataset$checklist, alternative = "two.sided", var.equal = FALSE)
# code goes here for all 3 cases
wilcox.test(Compare$treatment ~ Compare$time, mu=0, alt="two.sided", conf.int=T, conf.level=0.95, paired = F, exact=T, correct=T)
# code goes here
t.test(Compare$treatment ~ Compare$time, alternative = "two.sided", var.equal = FALSE)
# code goes here
#t.test(Compare$treatment ~ Compare$time, alternative = "two.sided", var.equal = FALSE)
levels(Compare$treatment)
# code goes here
#t.test(Compare$treatment ~ Compare$time, alternative = "two.sided", var.equal = FALSE)
levels(Compare$time)
# code goes here
#t.test(Compare$treatment ~ Compare$time, alternative = "two.sided", var.equal = FALSE)
levels(my_dataset$checklist)
# code goes here
#t.test(Compare$treatment ~ Compare$time, alternative = "two.sided", var.equal = FALSE)
str(my_dataset)
# code goes here
#t.test(Compare$treatment ~ Compare$time, alternative = "two.sided", var.equal = FALSE)
str(my_dataset)
str(Compare)
# code goes here
t.test(Compare$treatment ~ Compare$time, alternative = "two.sided", var.equal = FALSE)
# code goes here
t.test(Compare$time ~ Compare$treatment, alternative = "two.sided", var.equal = FALSE)
# code goes here
t.test(Compare$time ~ Compare$treatment, alternative = "less", var.equal = FALSE)
# code goes here
t.test(Compare$time ~ Compare$treatment, paired = TRUE, alternative = "two.sided")
t.test(Compare$time, Compare$treatment, paired=TRUE)
# code goes here
t.test(Compare$time ~ Compare$treatment, paired = TRUE, alternative = "two.sided")
t.test(Compare$time ~ Compare$treatment, paired=TRUE)
# code goes here for all 3 cases
wilcox.test(Compare$time ~ Compare$treatment, mu=0, alt="two.sided", conf.int=T, conf.level=0.95, paired = F, exact=T, correct=T)
wilcox.test(Compare$time ~ Compare$treatment, mu=0, alt="less", conf.int=T, conf.level=0.95, paired = F, exact=T, correct=T)
wilcox.test(Compare$time ~ Compare$treatment, mu=0, alt="two.sided", conf.int=T, conf.level=0.95, paired = T, exact=T, correct=T)
knitr::opts_chunk$set(echo = TRUE, tidy.opts = list(width.cutoff = 60), tidy = TRUE)
library(Sleuth3) # example datasets from textbook, "The Statistical Sleuth - A Course in
# Methods of Data Analysis (3rd Edition)"
library(MASS) # example dataset representing the sales of different models of cars in 1993
library(reshape2) # for formatting and aggregation of data frames
library(ggplot2) # for creating graphs
library(dplyr) # for data manipulation and clean-up
library(plotly) # for creating interactive web graphics from ggplot2 graphs
library(knitr) # required for generating PDF output
library(modeest) # required for `mfv()` function
library(nortest) # required for running Anderson-Darling test for normality
BookStore <- data.frame(
Price=c(99.34, 51.53, 20.45, 97.22, 61.89, 58.17, 61.63, 44.63, 96.69, 48.88,
55.98, 38.82, 45.14, 70.99, 48.85, 67.49, 53.90, 42.01, 61.35, 55.75),
Genre=factor(c('Science', 'Engineering', 'Art', 'Science', 'Math', 'Engineering', 'Art', 'Math', 'Engineering', 'Art',
'Math', 'Art', 'Art', 'Engineering', 'Math', 'Science', 'Engineering', 'Art', 'Science', 'Math'))
)
BookStore
Amazon <- data.frame(
Price=c(31.87, 58.94, 40.39, 117.99, 108.29, 78.44, 103.94, 96.44, 65.74, 63.49,
55.19, 92.65, 35.55, 104.49, 97.89, 74.87, 89.99, 19.99, 58.19, 80.89),
Genre=factor(c('Poetry', 'Mathematics', 'Psychology', 'Medical', 'Biology', 'Mathematics', 'Literature', 'Medical', 'Linguistics', 'Accounting',
'Physics', 'Psychology', 'Poetry', 'Medical', 'Medical', 'Literature', 'Accounting', 'Mathematics', 'Literature', 'Biology'))
)
Comparison <- data.frame(Store=rep(c("Bookstore", "Amazon"), each=20), Price=c(BookStore$Price, Amazon$Price), Genre=c(BookStore$Genre, Amazon$Genre))
Comparison
# t.test(weight ~ group)
t.test(Comparison$Price ~ Comparison$Store)
BeforeAmazon <- c(92.99, 50.98, 24.14, 101.50, 45.59, 69.95, 64.69, 58.29, 120.22, 49.90,
52.99, 47.25, 54.99, 80.00, 62.65, 69.59, 57.35, 40.95, 82.84, 63.29)
AfterAmazon <- BookStore$Price
t.test(BeforeAmazon, AfterAmazon, paired=TRUE)
require(ggplot2)
install.packages("reshape2")
install.packages('nortest')
install.packages("reshape2")
# code goes here
my_dataset <- read.csv("C:\\Users\\delyar\\Desktop\\CS 567\\Stats HW 1\\inspection.csv")
my_dataset
View(my_dataset)
View(my_dataset)
View(Compare)
# code goes here
my_dataset <- read.csv("C:\\Users\\delyar\\Desktop\\CS 567\\Stats HW 1\\inspection.csv")
my_dataset
# code goes here
mean(my_dataset$pbr)
mean(my_dataset$checklist)
median(my_dataset$pbr)
median(my_dataset$checklist)
boxplot(my_dataset)
#Shapiro: The Prob < W value listed in the output is the p-value. If the chosen alpha level is 0.05 and the p-value is less than 0.05, then the null hypothesis that the data are normally distributed is rejected. If the p-value is greater than 0.05, then the null hypothesis is not rejected.
shapiro.test(my_dataset$pbr)
shapiro.test(my_dataset$checklist)
# here we have p values of 0.63 and 0.18 respectively for pbr and checklist. both of them are bigger than 0.05 so both are normally distributed.
#if you have smaller sample size, Shapiro test is more preferred.
library(nortest)
ad.test(my_dataset$pbr)
ad.test(my_dataset$checklist)
#also for the ad test we can see that the p values are 0.47 and 0.24 that are bigger than 0.05 so we cannot reject the null hypothesis that the distributions are normal.
# Step 1: Randomly resample data points for each treatment 20000 times  (hint: you can use sample or replicate)
ExpandedPBR <- sample(my_dataset$pbr, 20000, replace = TRUE , prob = NULL)
ExpandedChecklist <- sample(my_dataset$checklist, 20000, replace = TRUE , prob = NULL)
# Step 2: Draw the histogram to compare the orignal with the bootstrap data for each treatment separately (hint: use `hist`)
hist(my_dataset$pbr)
hist(ExpandedPBR)
hist(my_dataset$checklist)
hist(ExpandedChecklist)
# Step 3: Check the normality of the bootstrapped data.
# from the visual method of the histograms we can tell that they are not sample but we can use AD test as well
ad.test(ExpandedPBR)
ad.test(ExpandedChecklist)
#from the AD test we have p-value < 2.2e-16 --> the null hypothesis that the data are normally distributed is rejected
# Step 4: Compare the descriptive statistics of original with the bootstrapped data.
mean(my_dataset$pbr)
mean(my_dataset$checklist)
mean(ExpandedPBR)
mean(ExpandedChecklist)
median(my_dataset$pbr)
median(my_dataset$checklist)
median(ExpandedPBR)
median(ExpandedChecklist)
boxplot(my_dataset$pbr, my_dataset$checklist, ExpandedPBR, ExpandedChecklist)
#code goes here (hint: use melt or reshape)
library("reshape2")
#one way:
melted <- melt(my_dataset)
#another way (I prefer this cause it has names for the variables and the values)
Compare <- data.frame(treatment=rep(c("pbr", "checklist"), each=30), time=c(my_dataset$pbr, my_dataset$checklist))
Compare
# code goes here
t.test(Compare$time ~ Compare$treatment, alternative = "two.sided", var.equal = FALSE)
#if the variances are equal we can also have it like this:
t.test(my_dataset$pbr ,my_dataset$checklist, alternative = "two.sided", var.equal=TRUE)
#we have p-value = 0.08656 --> higher than 0.05 --> not statistically significant
# code goes here
t.test(Compare$time ~ Compare$treatment, alternative = "less", var.equal = TRUE)
#p-value = 0.9567 --> higher than 0.05 --> not statistically significant
# code goes here
t.test(Compare$time ~ Compare$treatment, alternative = "two.sided", paired=TRUE, var.equal=TRUE)
# code goes here for all 3 cases
wilcox.test(Compare$time ~ Compare$treatment, mu=0, alt="two.sided", conf.int=T, conf.level=0.95, paired = F, exact=F, correct=T)
wilcox.test(Compare$time ~ Compare$treatment, mu=0, alt="less", conf.int=T, conf.level=0.95, paired = F, exact=F, correct=T)
wilcox.test(Compare$time ~ Compare$treatment, mu=0, alt="two.sided", conf.int=T, conf.level=0.95, paired = T, exact=F, correct=T)
#another way:
wilcox.test(Compare$time ~ Compare$treatment, alternative = "two.sided", var.equal=TRUE, var.equal=TRUE, exact = FALSE)
wilcox.test(Compare$time ~ Compare$treatment, alternative="less", var.equal=TRUE, exact = FALSE)
wilcox.test(Compare$time ~ Compare$treatment, alternative = "two.sided", paired=TRUE, exact = FALSE, var.equal=TRUE)
#only for part c the p-value is less than 0.05 -->If a p-value reported from a t test is less than 0.05, then that result is said to be statistically significant.
require(ggplot2)
install.packages("reshape2")
install.packages('nortest')
install.packages("reshape2")
install.packages("nortest")
#require(ggplot2)
#install.packages("reshape2")
#install.packages('nortest')
#require(ggplot2)
#install.packages("reshape2")
#install.packages('nortest')
install.packages("weatherData",repos = "http://cran.us.r-project.org")
require(ggplot2)
#install.packages("reshape2")
#install.packages('nortest')
install.packages("weatherData",repos = "http://cran.us.r-project.org")
require(ggplot2)
install.packages("reshape2")
#install.packages('nortest')
install.packages("weatherData",repos = "http://cran.us.r-project.org")
require(ggplot2)
install.packages("reshape2")
install.packages('nortest')
# code goes here
my_dataset <- read.csv("C:\\Users\\delyar\\Desktop\\CS 567\\Stats HW 1\\inspection.csv")
my_dataset
# code goes here
mean(my_dataset$pbr)
mean(my_dataset$checklist)
median(my_dataset$pbr)
median(my_dataset$checklist)
boxplot(my_dataset)
#Shapiro: The Prob < W value listed in the output is the p-value. If the chosen alpha level is 0.05 and the p-value is less than 0.05, then the null hypothesis that the data are normally distributed is rejected. If the p-value is greater than 0.05, then the null hypothesis is not rejected.
shapiro.test(my_dataset$pbr)
shapiro.test(my_dataset$checklist)
# here we have p values of 0.63 and 0.18 respectively for pbr and checklist. both of them are bigger than 0.05 so both are normally distributed.
#if you have smaller sample size, Shapiro test is more preferred.
library(nortest)
ad.test(my_dataset$pbr)
ad.test(my_dataset$checklist)
#also for the ad test we can see that the p values are 0.47 and 0.24 that are bigger than 0.05 so we cannot reject the null hypothesis that the distributions are normal.
# Step 1: Randomly resample data points for each treatment 20000 times  (hint: you can use sample or replicate)
ExpandedPBR <- sample(my_dataset$pbr, 20000, replace = TRUE , prob = NULL)
ExpandedChecklist <- sample(my_dataset$checklist, 20000, replace = TRUE , prob = NULL)
# Step 2: Draw the histogram to compare the orignal with the bootstrap data for each treatment separately (hint: use `hist`)
hist(my_dataset$pbr)
hist(ExpandedPBR)
hist(my_dataset$checklist)
hist(ExpandedChecklist)
# Step 3: Check the normality of the bootstrapped data.
# from the visual method of the histograms we can tell that they are not sample but we can use AD test as well
ad.test(ExpandedPBR)
ad.test(ExpandedChecklist)
#from the AD test we have p-value < 2.2e-16 --> the null hypothesis that the data are normally distributed is rejected
# Step 4: Compare the descriptive statistics of original with the bootstrapped data.
mean(my_dataset$pbr)
mean(my_dataset$checklist)
mean(ExpandedPBR)
mean(ExpandedChecklist)
median(my_dataset$pbr)
median(my_dataset$checklist)
median(ExpandedPBR)
median(ExpandedChecklist)
boxplot(my_dataset$pbr, my_dataset$checklist, ExpandedPBR, ExpandedChecklist)
# code goes here
my_dataset <- read.csv("C:\\Users\\delyar\\Desktop\\CS 567\\Stats HW 1\\inspection.csv")
my_dataset
getOptions("repos")
# code goes here
my_dataset <- read.csv("C:\\Users\\delyar\\Desktop\\CS 567\\Stats HW 1\\inspection.csv")
my_dataset
# code goes here
my_dataset <- read.csv("C:\\Users\\delyar\\Desktop\\CS 567\\Stats HW 1\\inspection.csv")
my_dataset
getOption("repos")
# code goes here
my_dataset <- read.csv("C:\\Users\\delyar\\Desktop\\CS 567\\Stats HW 1\\inspection.csv")
my_dataset
getOption("repos")
rmarkdown::render("file.Rmd", "pdf_document'")
# code goes here
my_dataset <- read.csv("C:\\Users\\delyar\\Desktop\\CS 567\\Stats HW 1\\inspection.csv")
my_dataset
getOption("repos")
rmarkdown::render("Delyar-Homework1.Rmd", "pdf_document'")
# code goes here
my_dataset <- read.csv("C:\\Users\\delyar\\Desktop\\CS 567\\Stats HW 1\\inspection.csv")
my_dataset
getOption("repos")
rmarkdown::render("Delyar-Homework1.Rmd", "pdf_document")
install.packages("nortest")
